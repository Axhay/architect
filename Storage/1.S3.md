
## Simple Storage Service

1. S3 can handle at least 3,500 PUT/COPY/PASTE/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket.
2. S3 is storage solution.
3. Glacier is archive solution.
4. S3 is an object storage.

Scenes:

1. SA is architecting a workload that requires a performant object based storage system that must be shared with multiple EC2 instances.
  - Company expects its user base to increase five times over one year.
  - Its application is hosted in one region and users RDS MySQL DB, an ELB ALB, and ECS to host the website and its micro services.
  - Which design changes should SA recommend to support expected growth?
        - **Move static files from ECS to Amazon S3.**

2. Company is evaluating S3 as data storage solution for their daily analyst reports.
  - Company has implemented stringent requirements concerning the security of the data at rest.
  - Specifically, CISO asked for the use of envelope encryption with separate permissions  for the use of an envelope key, automated rotation of the encryption keys and visibility into when an encryption key was used and by whom.
  - Which steps should SA take to satisfy the security requirements requested by CISO?
       - **Create S3 bucket to store reports and use Server-side encryption with AWS KMS-Managed keys (SSE-KMS).**

## S3 Pre-signed URLS:

1. Prevent unauthorized access to the reports.
2. Temporary access to protected assets.
3. Simple, occassional sharing of private files.
4. Frequent programmatic access to view or upload a file in an application.
5. Thumbnail easily created from originals if they are accidentally deleted.

Scenes:

3. App provides users to download private and personal files. 
  - Web server is overwhelmed with serving files for download.
  - It should reduce web server load and allow users to download only their files.
       - **Store files in S3 and have app generate S3 pre-signed URL for the user to download.**

4. Photo sharing website allows to generate thumbnail images of photo stored in S3.
  - DynamoDB table maintains location of photos and thumbnail are easily created from originals if accidentally deleted.
  - Storing thumbnails images at lowest cost
        - **S3**

5. Thousands of files stored in S3 bucket has well defined access pattern.
  - Files accessed multiple times a day for first 30 days.
  - Files rarely accessed in 90 days.
  - After that files never accessed again.
  - During first 120 days accessing files needs to take no more than few seconds.
  - Which lifecycle policy to minimize cost based on access pattern?
        - **S3 standard storage for first 30 days.Then move files to S3 Standard IA for next 90 days. Allow files to expire after that.**

6. SA is designing new social media application.
  - App must provide secure method of uploading profile photos.
  - Each user should be able to upload a photo into shared storage location for one week after their profile is created.
  - Which approach will meet all of these requirements?
       - **Use Amazon S3 with default private access policy and generate pre-signed URLs each time a new site profile is created.**

## S3 standard storage:

1. Files accessed multiple times a day for first 30 days.

Scenario:

7. Creating serverless web app
  - Access mapping data in hundreds of data files, each containing 30 KB of data.
  - Storage expected to grow to hundreds of terabytes.
  - Most cost effective storage.
       - **S3 standard storage**

8. SA is building online shopping app where users be able to browse items, add items and purchase items.
  - Images of items stored in S3 buckets organized by item category.
  - During testing, item images are still available to some users on deletion.
  - What is the flaw in design?
       - **S3 Delete requests are eventually consistent, which may cause other users to view items that have already been purchased.**

## S3 Standard Infrequent access:

1. Files rarely accessed in next 90 days.
2. Documents must be retreived immediately.
3. Highly available access but not frequent access.
4. Immediate access for batch jobs.
5. Media companies have more than 100TB of data to be stored and retrieved infrequently.

Scenes:

9. Company uses S3 for Backup of on premises environment.
  - Data must be retained at least for 7 years.
  - Data infrequently accessed for 35 days but needs to be instantly available.
  - After 35 days, data is rarely accessed
  - Most cost effective solution.
       - **Change backup so data goes to S3 Standard IA directly**
       - **Creates an S3 lifecycle policy that moves data to GLACIER storage class after 35 days.**

10. Company wants to store data for 5 years.
  - Company need to have immediate and highly available access to data in any point of time but not require frequent access.
  - What lifecycle action should be taken to meet requirements while reducing costs?
        - **Transition objects from S3 standard to S3 standard-IA.**

11. Company designs new service receiving locations updates from 3,600 rental cars every hour.
  - Cars upload location to S3 bucket.
  - Each location must be checked for distance from original rental location.
  - Which service process updates and scale automatically?
        - **S3 events and AWS lambda**

12. SA is designing a system that will store personally identifiable information (PII) to S3.
  - Due to compliance and regulatory requirements, both the master keys and unencrypted data should never be sent to AWS.
  - Which S3 encryption should SA choose?
       - **S3 client-side encryption with client-side master key**

13. Customer has service based out of Oregon, us and Paris, France.
  - App is storing data in S3 in Oregon and data is updated frequently.
  - Paris is experiencing slow response time when retrieving objects.
  - What should SA do to resolve slow response time for Paris office?
       - **Set up S3 bucket in Paris, and enable cross-region replication from Oregon bucket to Paris bucket.**

14. Company uses S3 for storing variety of files.
  - SA needs to design a feature that allow users to instantly restore any deleted files within 30 days of deletion.
  - Which is most cost efficient solution?
      - **Enable versioning and create lifecycle policy to remove expired versions after 30 days.**

15. One company wants to share contents of S3 bucket with other company.
  - sec mandate that only other companies AWS account has access to contents of S3 bucket.
  - Which feature allow secure access to S3 bucket.
       - **Bucket policy**

16. Company policy requires that all data stored in S3 is encrypted.
  - Company wants to use option of least overhead and do not want to manage any encryption keys.
  - Which option meets companys requirement?
       - **Server Side Encryption (SSE-S3)**

17. Company wants to ensure that all files created in S3 bucket us-east-1 are also available in another bucket in ap-southeast-2.
  - Which option represents the simplest way to implement these changes?
       - **Enable versioning and configure cross-region replication from bucket in us-east-1 to bucket in ap-southeast-2.**

18. SA is architecting a workload that needs performant object based storage system that must be shared with multiple EC2 instances.
  - Which AWS service meets these requirements?
       - **Amazon S3.**

19. Company has an app that store sensitive data. 
  - Companies are required to store multiple copies of its data.
  - What would be MOST resilient and cost effective option to meet this requirement?
       - **S3**

20. SA is designing solution to store large quantities of event data in S3.
  - Architect anticipates that workload will exceed 100 requests each second.
  - What should SA do in S3 to optimize requirements?
       - **Randomize a key name prefix.**

21. Companies dev teams plans to create S3 bucket containing millions of images.
  - Team want to maximize read performance of S3.
  - Which naming scheme company should use?
       - **Add a date as the prefix.**

22. Company storing app data in S3 buckets across multiple AWS regions.
  - Company policy requires that encryption keys be generated at company headquarters, but encryption keys be stored in AWS after generation.
  - SA plans to configure cross region replication.
  - Which sol will encrypt data requiring least amount of operational overhead?
       - **Configure S3 buckets to use Server-side encryption with AWS KMS-Managed Keys (SSE-KMS) with imported key material in both regions.**

23. SA must design a storage solution for incoming billing reports in CSV format.
  - Data does not need to be scanned frequently and is discarded after 30 days.
  - Which service will be MOST cost-effective in meeting these requirements?
       - **Write the files to an S3 bucket and use Amazon Athena to query the data.**

24. S3 bucket have the policy to delete the files automatically after 30 day retention period has elapsed further saving money.
  - Company uses S3  for storing variety of files.
  - SA needs to  design feature that will allow users to instantly restore any deleted files within 30 days of deletion. 
  - Which is the most cost efficient solution ?
       - **Enable versioning and create a lifecycle policy to remove expired versions after 30 days.**

25. Company generates invoices and makes it available online.
  - Stored as PDF in S3 bucket.
  - Customers see invoice during start of the month.
  - Past invoice needs to be immediately available.
  - Concerns over rising storage costs as company gains more customers.
  - Most cost effective method to store data?
       - **S3 for current invoices**
       - **Setup lifecycle rules to migrate invoices to S3 Standard IA after 30 days.**

26. App produces monthly reports that must be immediately accessible up to 7 days.
  - After 7 days, data can be archived.
  - Archived data be retrievable within 24 hrs of request.
  - Most cost effective approach to satisfy compliance requirement?
        - **Store data in S3 standard storage with lifecycle rule to transition the data to GLACIER storage after 7 days.**

## Glacier storage:

1. Transition data to Glacier storage after 7 days.
2. Archived data: ex after 7 days, data can be archived.
3. Data is rarely accessed after 35 days.
4. Readily available means glacier storage.
5. Cost of Glacier is less than IA.
6. Customers can store data for as little as $1 per terabyte per month. Data stored in Glacier is immutable, meaning after an archive is created it cannot be updated.

Scenes:

27. App generates audit logs of operational activities
  - Compliance requirements mandates that the app retains logs for 5 years.
  - How can requirements be met?
       - **Save the logs in an amazon glacier vault and use the vault lock feature.**

28. Company processed 10TB of raw data to generate quarterly reports.
  - Unlikely to be used again, raw data needs to be preserved for compliance and auditing purpose.
  - Most cost effective way to store data in aws?
       - **Glacier**

29. Media company store 10TB of audio recordings:
  - Retreival happens infrequently and requestors agree on an 8-hour turnaround time.
  - What is the MOST cost effective solution to store files?
       - **Amazon Glacier**

30. SA is asked to improve fault tolerance of existing python application.
  - The web application places 1MB images in S3 bucket.
  - App then uses single T2.large instance to transform image to include watermark with companys brand before writing the image back to S3 bucket.
  - What should SA recommend to increase fault tolerance of the solution?
       - **Convert the code to lambda function triggered by S3 events.**

## More:
1. Stores all versions of an object (including all writes and even if you delete an object).
2. Great backup tool.
3. Once enabled, versioning cannot be disabled, only suspended.
4. Integrates with lifecycle rules.
5. Secure, durable, highly scalable object storage for devs and IT teams.
6. Safe place to store your files.
7. Object based storage.
8. Data is spread across multiple devices and facilities.
9. Files can be from 0 Bytes to 5TB.
10. There is unlimited storage.
11. Files are stored in buckets.
12. S3 is universal namespace. Name must be unique globally.
13. When you upload file to S3, you receive HTTP 200 code if upload was successful.
14. S3 is object based. Think of object as files.
15. Object consists of:
 - Key (name of object)
 - Value (this is simply data and is made up of sequence of bytes)
 - Version ID (important for versioning)
 - Metadata (Data about data you are storing)
 - Subresources (ACL, Torrents)
16. If you write a new file and read it immediately afterwards, you will be able to view that data.
17. If you update an existing file or delete a file and read it immediately, you may get older version. Basically changes to objects can take a little bit of time to propagate.
18. Charge for S3 in the following way:
Storage, requests, Data transfer, Transfer acceleration, Cross region replication pricing.
19. S3 transfer acceleration.
Uses Cloudfront edge network to accelerate your uploads to S3.
20. Instead of uploading directly to S3 bucket, you can use a distinct URL to upload directly to an edge location which will then transfer that file to S3.
21. You get a distinct URL to upload to.
22. Buckets are universal namespace.
23. Upload an object to S3 receive a HTTP 200 code.
24. Control access to buckets using either a bucket ACL or using Bucket policies.
25. S3 storage classes: S3 standard, S3-IA, S3 One Zone- IA, S3-Intelligent Tiering, S3 Glacier, S3 Glacier Deep Archive.
26. S3 standard: Designed to sustain loss of 2 facilities concurrently. AZ>=3. First byte latency is in milliseconds.
27.  S3- IA (Infrequently accessed): For data that is accessed less frequently. It needs rapid access when needed. Lower fee than S3, but you are charged a retreival fee, first byte latency is in milliseconds. Retreival fee per GB retreived. Min storage duration: 30 days.
28. S3 One Zone  - IA: Lower cost option for infrequently accessed data. AZ = 1. Retreival fee : per GB retreived. Min storage duration: 30 days. 
29. S3 intelligent tiering:
Optimize cost by automatically moving data to the most cost effective access tier, without performance impact of operational overhead. AZ>=3. Min storage duration charge: 30 days.
30. S3 glacier: secure, durable, and low cost storage class for data archiving. Can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. Retrieval times configurable from minutes to hours. Min storage duration charge: 90 days. Retreival fee per GB retrieved.
31. S3 Glacier Deep Archive: S3s lowest cost storage class where retreival time of 12 hrs is acceptable. First byte latency is in select hours. Retreival fee is per GB retreived. Min storage duration charge: 180 days.






## Tips:
1. Versioning can be enabled on both source and destination buckets.
2. Regions must be unique.
3. Files in a bucket are not replicated automatically.
4. Delete markers are not replicated.
5. All newly created buckets are PRIVATE.
6. Can setup access control to your buckets using bucket policies and access control lists.
7. S3 buckets can be configured to create access logs which log all requests made to S3 bucket.
8. Encryption in transit by SSL/TLS
9. Encryption at REST(Server side) is achieved by S3 Managed keys O SS3-S3, AWS Key management service, Managed Keys - SS3-KMS, Server side encryption with customer provided keys - SS3-C
10. Client side encryption.
