## Kinesis

1. Kinesis=event=1000 request
2. Amazon Kinesis Data Firehose is the easiest way to reliably load streaming data into data lakes, data stores, and analytics tools. It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration.
3. Shards scale linearly, so adding shards to a stream will add 1MB per second of ingestion, and emit data at a rate of 2MB per second for every shard added. Ten shards will scale a stream to handle 10MB (10,000 PUTs) of ingress, and 20MB of data egress per second".
4. Docker makes it easy to build and run distributed microservices architecures, deploy your code with standardized continuous integration and delivery pipelines, build highly-scalable data processing systems, and create fully-managed platforms for your developers. Docker also provides big data processing as a service. (https://aws.amazon.com/docker/).
5. Input – The streaming source for your application. You can select either a Kinesis data stream or a Kinesis Data Firehose data delivery stream as the streaming source. In the input configuration, you map the streaming source to an in-application input stream. The in-application stream is like a continuously updating table upon which you can perform the SELECT and INSERT SQL operations. In your application code, you can create additional in-application streams to store intermediate query results.
6. collect = kinesis
Data warehouse = redshift

Scenes:

1. SA designed a system based on Kinesis Data Streams.
  - After workflow was put in production, company noticed it performed slowly and identified Kinesis Data Streams as the problem.
  - One of the streams has a total of 10 Mb/s throughput.
  - What should SA do to improve performance?
       - **Run the UpdateShardCount command to increase the number of shards in the stream**
  Shards scale linearly, so adding shards to a stream will add 1MB per second of ingestion, and emit data at a rate of 2MB per second for every shard added. Ten shards will scale a stream to handle 10MB (10,000 PUTs) of ingress, and 20MB of data egress per second"

2. Company is building a critical ingestion service on AWS that will receive 1,000 incoming events per second.
 - The events must be processed in order, and no events may be lost.
 - Multiple applications need to process each event.
 - The company will expose the service as RESTful calls through API gateway.
 - What should SA use to receive the events based on these requirements?
       - **Amazon Kinesis Data Stream**
   Kinesis=event=1000 request
   
3. SA is designing a microservice to process records from Kinesis Streams. 
 - The metadata must be stored in Amazon DynamoDB. 
 - Microservice must be capable of concurrently processing 10,000 records daily as they arrive in the Kinesis stream.
 - The MOST scalable way to design the microservice is:
      - **As a Docker container running on Amazon ECS.**
  Docker makes it easy to build and run distributed microservices architecures, deploy your code with standardized continuous integration and delivery pipelines, build highly-scalable data processing systems, and create fully-managed platforms for your developers. Docker also provides big data processing as a service. (https://aws.amazon.com/docker/)

4. Org must process a stream of large-volume hashtag data in real time and needs to run custom SQL queries on the data to get insights on certain tags. 
 - The org needs this solution to be elastic and does not want to manage clusters. 
 - Which of the AWS services meets these requirements?
       - **Amazon Kinesis Data Analytics**
  Input – The streaming source for your application. You can select either a Kinesis data stream or a Kinesis Data Firehose data delivery stream as the streaming source. In the input configuration, you map the streaming source to an in-application input stream. The in-application stream is like a continuously updating table upon which you can perform the SELECT and INSERT SQL operations. In your application code, you can create additional in-application streams to store intermediate query results.

5. Online company wants to conduct real-time sentiment analysis about its products from its social media channels using SQL. 
 - Which of the following solutions has the LOWEST cost and operational behavior?
    - **Configure the input stream using Amazon Kinesis Data Streams. Use Amazon Kinesis Data Analytics to write SQL queries against the stream.**

6. Company must collect temperature data from thousands of remote weather divisions. 
 - The company must also store this data in a data warehouse to run aggregations and visualizations.
 - Which services will meet these requirements?
       - **Amazon Kinesis Data Firehouse**
       - **Amazon Redshift**
    collect = kinesis
    Data warehouse = redshift

7. App is running on EC2 instance in private subnet.
 - App needs to read and write data into Kinesis Data Streams, and corporate policy requires that this traffic should not go to the Internet.
 - How can these requirements be met?
    - **Configure an interface VPC endpoint for Kinesis and route all traffic to Kinesis through the gateway VPC endpoint.**
  
8. Company website receives 50,000 requests each second, and company wants to use multiple apps to analyze navigation patterns of the users on their website so that the experience can be personalized.
 - What can SA use to collect page clicks for the website and process them sequentially for each user?
    - **Amazon Kinesis Stream**

9. A user is testing a new service that receives location updates from 3,600 rental cars every hour. 
 - Which service will collect data and autoscale to accommodate production overload?
    - **Amazon Kinesis Firehose**
    
10. Manufacturing company captures data from machines running at customer sites. Currently, thousands of machines send data every 5 mins, and this is expected to grow to hundreds of thousands of machines in the near future.
 - The data is logged with the intent to be analyzed in the future as needed. What is the SIMPLEST method to store this streaming data at scale?
       - **Create an Amazon Kinesis Firehouse delivery stream to store the data in Amazon S3.**
